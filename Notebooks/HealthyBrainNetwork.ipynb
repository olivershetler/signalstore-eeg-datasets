{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:13:07.844415800Z",
     "start_time": "2024-07-03T02:13:07.778989Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To be able to make edits to repo without having to restart notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:13:13.464613800Z",
     "start_time": "2024-07-03T02:13:11.773782600Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path(\"/Users/dtyoung/Documents/childmind/signalstore-eeg-datasets/HealthyBrainNetworkDataExample/ds004186\")\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from signalstore import UnitOfWorkProvider\n",
    "from mongomock import MongoClient\n",
    "#from pymongo import MongoClient\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from fsspec import get_mapper\n",
    "from fsspec.implementations.dirfs import DirFileSystem\n",
    "import fsspec\n",
    "import mne\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthy Brain Network Data - Resting state\n",
    "\n",
    "This is an excerpt of the Healthy Brain Network data ([data paper](https://www.nature.com/articles/sdata2017181)). The resting state portion as been formatted with BIDS ([Brain Imaging Data Structure](https://bids-specification.readthedocs.io/en/stable/)) format, and made publicly available on [Openneuro](https://openneuro.org/datasets/ds004186/versions/2.0.0) (it's a large dataset so browsing latency might be lagging)\n",
    "\n",
    "## EEG Files\n",
    "Data is organized by subject. Each subject (`sub-*`) directory has an `eeg` directory storing the eeg data and its associated metadata.\n",
    "`*_eeg.fdt` and `*_eeg.set`: EEG data in EEGLAB format\n",
    "\n",
    "## Experiment Information\n",
    "Subjects 1-17 were instructed to attend to 'Twenty Thousand Leagues Under the Sea' (20000), played in the left ear\n",
    "Subjects 18-33 were instructed to attend to 'Journey to the Centre of the Earth' (Journey), played in the right ear\n",
    "\n",
    "## Behavioral Data\n",
    "score: Comprehension question scores for attended and unattended stories.\n",
    "Format: Subjects x Run x Story (1=Attended, 2=Unattended)\n",
    "\n",
    "## Stimuli Data Files\n",
    "\n",
    "wordVec = List of all the content words for a given trial\n",
    "onset_time = Onset time of the word in the corresponding cell of 'wordVec' (given in seconds)\n",
    "offset_time = Offset time of the word in the corresponding cell of 'wordVec' (given in seconds)\n",
    "sentence_boundaries = Time of sentence close (in seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:19:35.666921500Z",
     "start_time": "2024-07-03T02:19:35.573455400Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_eeg_data(bids_data_path):\n",
    "    subjects = [bids_dir for bids_dir in os.listdir(bids_data_path) if bids_dir.startswith('sub-')]\n",
    "    print('subjects', subjects)\n",
    "    for sub_n, subject_dir in enumerate(subjects):\n",
    "        subject = subject_dir.split('-')[1]\n",
    "        subject_dir_path = bids_data_path / subject_dir\n",
    "        eeg_dir = subject_dir_path / \"eeg\"\n",
    "        sub_n += 1\n",
    "\n",
    "        tasks = ['EC', 'EO']\n",
    "        runs  = [list(range(1, 6)), list(range(1, 6))]\n",
    "        # list run mat files\n",
    "        # runs = os.listdir(subject_dir_path)\n",
    "        for t, task in enumerate(tasks):\n",
    "            for run in runs[t]:\n",
    "                # get file by name pattern subject_dir*task*run_eeg.set\n",
    "                raw_file = eeg_dir / f\"{subject_dir}_task-{task}_run-{run}_eeg.set\"\n",
    "                print('raw file', raw_file)\n",
    "                if not os.path.exists(raw_file):\n",
    "                    continue\n",
    "\n",
    "                EEG = mne.io.read_raw_eeglab(os.path.join(raw_file), preload=True)\n",
    "                eeg_data = EEG.get_data()\n",
    "\n",
    "                print('data shape:', eeg_data.shape)\n",
    "                \n",
    "                eeg_json_file = eeg_dir / f\"{subject_dir}_task-{task}_run-{run}_eeg.json\"\n",
    "                eeg_json = json.load(eeg_json_file.open())\n",
    "                fs = int(eeg_json['SamplingFrequency'])\n",
    "                max_time = eeg_data.shape[0] / fs\n",
    "                time_steps = np.linspace(0, max_time, eeg_data.shape[0]).squeeze() # in seconds\n",
    "\n",
    "                channel_coords_file = eeg_dir / f\"{subject_dir}_task-{task}_run-{run}_channels.tsv\"\n",
    "                channel_coords = pd.read_csv(channel_coords_file, sep='\\t') \n",
    "                # get channel names from channel_coords\n",
    "                channel_names = channel_coords['name'].values\n",
    "                # print('channel coords names', channel_names)\n",
    "                # print(len(channel_names))\n",
    "                eeg_xarray = xr.DataArray(\n",
    "                    data=eeg_data,\n",
    "                    dims=['time', 'channel'],\n",
    "                    # coords={\n",
    "                    #     'time': time_steps,\n",
    "                    #     'channel': channel_names\n",
    "                    # },\n",
    "                    attrs={\n",
    "                        'schema_ref': 'eeg_signal',\n",
    "                        'data_name': f\"{subject_dir}_task-{task}_run-{run}\",\n",
    "                        'subject': f'{subject}',\n",
    "                        'version_timestamp': 0,\n",
    "                        'task': task,\n",
    "                        'session_run': run,\n",
    "                        'sampling_frequency': fs,\n",
    "                    }\n",
    "                )\n",
    "                yield eeg_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:13:16.127758Z",
     "start_time": "2024-07-03T02:13:15.907346500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "property model:  version_timestamp\n",
      "property model:  schema_ref\n",
      "property model:  schema_type\n",
      "property model:  schema_name\n",
      "property model:  schema_title\n",
      "property model:  schema_description\n",
      "property model:  data_name\n",
      "property model:  time_of_save\n",
      "property model:  time_of_removal\n",
      "property model:  record_type\n",
      "property model:  modality\n",
      "property model:  json_schema\n",
      "property model:  has_file\n",
      "property model:  unit_of_measure\n",
      "property model:  dimension_of_measure\n",
      "property model:  acquisition\n",
      "property model:  acquisition_date\n",
      "property model:  import_date\n",
      "property model:  acquisition_notes\n",
      "property model:  data_dimensions\n",
      "property model:  shape\n",
      "property model:  dtype\n",
      "property model:  session_description\n",
      "property model:  session_date\n",
      "property model:  session_time\n",
      "property model:  session_duration\n",
      "property model:  session_notes\n",
      "property model:  session_run\n",
      "property model:  data_ref\n",
      "property model:  start_time\n",
      "property model:  duration\n",
      "property model:  duration_unit\n",
      "property model:  animal_species\n",
      "property model:  age\n",
      "property model:  age_unit\n",
      "property model:  age_lower_bound\n",
      "property model:  age_upper_bound\n",
      "property model:  animal_id\n",
      "property model:  tetrode_id\n",
      "property model:  tetrode_depth\n",
      "property model:  genotype\n",
      "property model:  animal_strain\n",
      "property model:  stimulus_type\n",
      "property model:  stimulus_id\n",
      "property model:  stimulus_description\n",
      "property model:  recording_length\n",
      "property model:  sample_rate\n",
      "property model:  arena_shape\n",
      "property model:  arena_description\n",
      "property model:  study_description\n",
      "property model:  arena_height\n",
      "property model:  arena_width\n",
      "property model:  diameter\n",
      "property model:  arena_side_length\n",
      "property model:  arena_radius\n",
      "property model:  spike_count\n",
      "property model:  subject\n",
      "property model:  sampling_frequency\n",
      "property model:  attending_direction\n",
      "property model:  attending_story\n",
      "property model:  attend_score\n",
      "property model:  nonattend_score\n",
      "property model:  original_length\n",
      "property model:  story\n",
      "property model:  task\n",
      "meta model:  record_metamodel\n",
      "meta model:  xarray_dataarray_metamodel\n",
      "domain model:  eeg_signal\n",
      "domain model:  session\n",
      "domain model:  stimuli_record\n",
      "domain model:  wordvec\n",
      "domain model:  offset_times\n",
      "domain model:  onset_times\n",
      "domain model:  sentence_boundaries\n",
      "domain model:  envelope\n"
     ]
    }
   ],
   "source": [
    "filesystem = LocalFileSystem()\n",
    "# tmp_dir = TemporaryDirectory()\n",
    "# print(tmp_dir.name)\n",
    "\n",
    "# Create data storage location\n",
    "dataset_name = \"healthy_brain_network\"\n",
    "store_path = Path(\"/Users/dtyoung/Documents/childmind/signalstore-eeg-datasets/HealthyBrainNetworkDataExample/signalstore\")\n",
    "\n",
    "# Create a directory for the dataset\n",
    "if not os.path.exists(store_path):\n",
    "    os.makedirs(store_path)\n",
    "\n",
    "tmp_dir_fs = DirFileSystem(\n",
    "    store_path,\n",
    "    filesystem=filesystem\n",
    ")\n",
    "client = MongoClient()\n",
    "memory_store = {}\n",
    "uow_provider = UnitOfWorkProvider(\n",
    "    mongo_client=client,\n",
    "    filesystem=tmp_dir_fs,\n",
    "    memory_store=memory_store\n",
    ")\n",
    "import json\n",
    "cwd = Path.cwd()\n",
    "domain_models_path = cwd.parent / f\"DomainModels/{dataset_name}/data_models.json\"\n",
    "metamodel_path = cwd.parent / f\"DomainModels/{dataset_name}/metamodels.json\"\n",
    "property_path = cwd.parent / f\"DomainModels/{dataset_name}/property_models.json\"\n",
    "\n",
    "with open(metamodel_path) as f:\n",
    "    metamodels = json.load(f)\n",
    "\n",
    "with open(property_path) as f:\n",
    "    property_models = json.load(f)\n",
    "    \n",
    "# for metamodel in metamodels:\n",
    "# with uow_provider('cocktail-party') as uow:\n",
    "#     print(f\"Adding model {metamodel['schema_name']} to domain_models store.\")\n",
    "#     uow.domain_models.add(metamodel)\n",
    "#     model = uow.domain_models.get(metamodel['schema_name'])\n",
    "#     print(model['schema_name'])\n",
    "#     uow.commit()\n",
    "\n",
    "# load domain models json file\n",
    "with open(domain_models_path) as f:\n",
    "    domain_models = json.load(f)\n",
    "    \n",
    "with uow_provider(dataset_name) as uow:\n",
    "    for property_model in property_models:\n",
    "        uow.domain_models.add(property_model)\n",
    "        model = uow.domain_models.get(property_model['schema_name'])\n",
    "        print('property model: ', model['schema_name'])\n",
    "    for metamodel in metamodels:\n",
    "        uow.domain_models.add(metamodel)\n",
    "        model = uow.domain_models.get(metamodel['schema_name'])\n",
    "        print('meta model: ', model['schema_name'])\n",
    "    for domain_model in domain_models:\n",
    "        uow.domain_models.add(domain_model)\n",
    "        model = uow.domain_models.get(domain_model['schema_name'])\n",
    "        print('domain model: ', model['schema_name'])\n",
    "        uow.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Subject 30 Run 2 has data shape (2, 7681), and eeg data shape (128, 7681) for some reason, added the code in the load_eeg_data function to transpose the mastoid data if the second dimension is not 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T02:23:15.444866400Z",
     "start_time": "2024-07-03T02:19:59.783246300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects ['sub-NDARZZ993CEV']\n",
      "raw file /Users/dtyoung/Documents/childmind/signalstore-eeg-datasets/HealthyBrainNetworkDataExample/ds004186/sub-NDARZZ993CEV/eeg/sub-NDARZZ993CEV_task-EC_run-1_eeg.set\n",
      "Reading /Users/dtyoung/Documents/childmind/signalstore-eeg-datasets/HealthyBrainNetworkDataExample/ds004186/sub-NDARZZ993CEV/eeg/sub-NDARZZ993CEV_task-EC_run-1_eeg.fdt\n",
      "Reading 0 ... 19997  =      0.000 ...    39.994 secs...\n",
      "data shape: (129, 19998)\n",
      "adding data\n"
     ]
    },
    {
     "ename": "MongoDAOTypeError",
     "evalue": "Invalid type <class 'xarray.core.dataarray.DataArray'> for argument time_threshold. Must be one of (<class 'datetime.datetime'>, <class 'NoneType'>).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMongoDAOTypeError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madding data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m uow_provider(dataset_name) \u001b[38;5;28;01mas\u001b[39;00m uow:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43muow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpurge\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg_xarray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# uow.data.add(eeg_xarray)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     uow\u001b[38;5;241m.\u001b[39mcommit()\n",
      "File \u001b[0;32m~/Documents/childmind/signalstore-eeg-datasets/.venv/lib/python3.11/site-packages/signalstore/store/repositories.py:748\u001b[0m, in \u001b[0;36mDataRepository.purge\u001b[0;34m(self, time_threshold)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpurge\u001b[39m(\u001b[38;5;28mself\u001b[39m, time_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    747\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Purge (permanently delete) records marked for deletion.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_records\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpurge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mpurge(time_threshold\u001b[38;5;241m=\u001b[39mtime_threshold)\n",
      "File \u001b[0;32m~/Documents/childmind/signalstore-eeg-datasets/.venv/lib/python3.11/site-packages/signalstore/store/data_access_objects.py:267\u001b[0m, in \u001b[0;36mMongoDAO.purge\u001b[0;34m(self, time_threshold)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpurge\u001b[39m(\u001b[38;5;28mself\u001b[39m, time_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    266\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Purges deleted documents from the repository older than the time threshold.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mdelete_many({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_of_removal\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$ne\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}})\n",
      "File \u001b[0;32m~/Documents/childmind/signalstore-eeg-datasets/.venv/lib/python3.11/site-packages/signalstore/store/data_access_objects.py:285\u001b[0m, in \u001b[0;36mMongoDAO._check_args\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MongoDAOArgumentNameError(\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid keyword argument name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, arg_types) \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MongoDAOTypeError(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Must be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n",
      "\u001b[0;31mMongoDAOTypeError\u001b[0m: Invalid type <class 'xarray.core.dataarray.DataArray'> for argument time_threshold. Must be one of (<class 'datetime.datetime'>, <class 'NoneType'>)."
     ]
    }
   ],
   "source": [
    "for eeg_xarray in load_eeg_data(data_path):\n",
    "    print('adding data')\n",
    "    with uow_provider(dataset_name) as uow:\n",
    "        uow.data.add(eeg_xarray)\n",
    "        \n",
    "        uow.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EC_run-1', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EC', 'session_run': 1, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 51, 691132, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EC_run-2', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EC', 'session_run': 2, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 51, 779608, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EC_run-3', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EC', 'session_run': 3, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 51, 854820, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EC_run-4', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EC', 'session_run': 4, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 51, 929877, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EC_run-5', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EC', 'session_run': 5, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 52, 7714, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EO_run-1', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EO', 'session_run': 1, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 52, 64901, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EO_run-2', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EO', 'session_run': 2, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 52, 112449, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EO_run-3', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EO', 'session_run': 3, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 52, 156011, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EO_run-4', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EO', 'session_run': 4, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 52, 199602, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n",
      "{'schema_ref': 'eeg_signal', 'data_name': 'sub-NDARZZ993CEV_task-EO_run-5', 'subject': 'NDARZZ993CEV', 'version_timestamp': 0, 'task': 'EO', 'session_run': 5, 'sampling_frequency': 500, 'has_file': True, 'time_of_save': datetime.datetime(2024, 7, 23, 19, 31, 52, 247472, tzinfo=datetime.timezone.utc), 'time_of_removal': None}\n"
     ]
    }
   ],
   "source": [
    "with uow_provider(dataset_name) as uow:\n",
    "    query = {\n",
    "        # \"schema_ref\": \"eeg_signal\",\n",
    "        \"subject\": \"NDARZZ993CEV\",\n",
    "    }\n",
    "    sessions = uow.data.find(query)\n",
    "    print(len(sessions))\n",
    "    for i in range(len(sessions)):\n",
    "        print(sessions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
